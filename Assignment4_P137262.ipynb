{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjYGJCF72qq/peZbe5ZsHS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azrazainol/STQD6324_Assignment_04/blob/main/Assignment4_P137262.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MovieLens Analysis\") \\\n",
        "    .config(\"spark.cassandra.connection.host\", \"127.0.0.1\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 1: Parse the u.user file\n",
        "def parse_user(line):\n",
        "    fields = line.split('|')\n",
        "    return Row(user_id=int(fields[0]), age=int(fields[1]), gender=fields[2], occupation=fields[3], zip=fields[4])\n",
        "\n",
        "def parse_data(line):\n",
        "    fields = line.split(\"\\t\")\n",
        "    return Row(user_id=int(fields[0]), movie_id=int(fields[1]), rating=int(fields[2]), time=int(fields[3]))\n",
        "\n",
        "def parse_item(line):\n",
        "    fields = line.split(\"|\")\n",
        "    return Row(movie_id=int(fields[0]), title=fields[1], release_date=fields[2], vid_release_date=fields[3], url=fields[4],\n",
        "               unknown=int(fields[5]), action=int(fields[6]), adventure=int(fields[7]), animation=int(fields[8]),\n",
        "               children=int(fields[9]), comedy=int(fields[10]), crime=int(fields[11]), documentary=int(fields[12]),\n",
        "               drama=int(fields[13]), fantasy=int(fields[14]), film_noir=int(fields[15]), horror=int(fields[16]),\n",
        "               musical=int(fields[17]), mystery=int(fields[18]), romance=int(fields[19]), sci_fi=int(fields[20]),\n",
        "               thriller=int(fields[21]), war=int(fields[22]), western=int(fields[23]))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a SparkSession\n",
        "    spark = SparkSession.builder.appName(\"MovieLens Analysis\").config(\"spark.cassandra.connection.host\", \"127.0.0.1\").getOrCreate()\n",
        "\n",
        "    # Parse data files\n",
        "    lines1 = spark.sparkContext.textFile(\"hdfs:///user/maria_dev/ml-100k/u.user\")\n",
        "    users = lines1.map(parse_user)\n",
        "\n",
        "    lines2 = spark.sparkContext.textFile(\"hdfs:///user/maria_dev/ml-100k/u.data\")\n",
        "    ratings = lines2.map(parse_data)\n",
        "\n",
        "    lines3 = spark.sparkContext.textFile(\"hdfs:///user/maria_dev/ml-100k/u.item\")\n",
        "    names = lines3.map(parse_item)\n",
        "\n",
        "    # Convert to DataFrames\n",
        "    usersDataset = spark.createDataFrame(users)\n",
        "    ratingsDataset = spark.createDataFrame(ratings)\n",
        "    namesDataset = spark.createDataFrame(names)\n",
        "\n",
        "    # Write to Cassandra\n",
        "    usersDataset.write \\\n",
        "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "        .mode('append') \\\n",
        "        .options(table=\"users\", keyspace=\"movielens\") \\\n",
        "        .save()\n",
        "\n",
        "    ratingsDataset.write \\\n",
        "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "        .mode('append') \\\n",
        "        .options(table=\"ratings\", keyspace=\"movielens\") \\\n",
        "        .save()\n",
        "\n",
        "    namesDataset.write \\\n",
        "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "        .mode('append') \\\n",
        "        .options(table=\"names\", keyspace=\"movielens\") \\\n",
        "        .save()\n",
        "\n",
        "    # Read from Cassandra into DataFrames\n",
        "    readUsers = spark.read \\\n",
        "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "        .options(table=\"users\", keyspace=\"movielens\").load()\n",
        "\n",
        "    readRatings = spark.read \\\n",
        "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "        .options(table=\"ratings\", keyspace=\"movielens\").load()\n",
        "\n",
        "    readNames = spark.read \\\n",
        "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "        .options(table=\"names\", keyspace=\"movielens\").load()\n",
        "\n",
        "    # Create temporary views for SQL querying\n",
        "    readUsers.createOrReplaceTempView(\"users\")\n",
        "    readRatings.createOrReplaceTempView(\"ratings\")\n",
        "    readNames.createOrReplaceTempView(\"names\")\n",
        "\n",
        "    # Execute SQL queries\n",
        "\n",
        "    # i) Calculate the average rating for each movie (top ten results)\n",
        "    sql_query_i = spark.sql(\"\"\"\n",
        "    SELECT movie_id, AVG(rating) AS avg_rating\n",
        "    FROM ratings\n",
        "    GROUP BY movie_id\n",
        "    ORDER BY avg_rating DESC\n",
        "    LIMIT 10\n",
        "    \"\"\")\n",
        "    print(\"Average Rating by Movie\")\n",
        "    sql_query_i.show()\n",
        "\n",
        "    # ii) Identify the top ten movies with the highest average ratings\n",
        "    sql_query_ii = \"\"\"\n",
        "    SELECT n.title, AVG(r.rating) AS avg_rating\n",
        "    FROM ratings r\n",
        "    JOIN names n ON r.movie_id = n.movie_id\n",
        "    GROUP BY n.title\n",
        "    ORDER BY avg_rating DESC\n",
        "    LIMIT 10\n",
        "    \"\"\"\n",
        "    print(\"Movies with Highest Average Ratings\")\n",
        "    spark.sql(sql_query_ii).show()\n",
        "\n",
        "    # iii) Find the users who have rated at least 50 movies and identify their favourite movie genres\n",
        "    sql_query_iii = \"\"\"\n",
        "    SELECT u.user_id, u.age, u.occupation, u.gender, g.genre, COUNT(*) AS count_ratings\n",
        "    FROM users u\n",
        "    JOIN ratings r ON u.user_id = r.user_id\n",
        "    JOIN names n ON r.movie_id = n.movie_id\n",
        "    LATERAL VIEW explode(array(\"unknown\", \"action\", \"adventure\", \"animation\", \"children\", \"comedy\", \"crime\", \"documentary\",\n",
        "        \"drama\", \"fantasy\", \"film_noir\", \"horror\", \"musical\", \"mystery\", \"romance\", \"sci_fi\", \"thriller\", \"war\", \"western\")) g AS genre\n",
        "    GROUP BY u.user_id, u.age, u.occupation, u.gender, g.genre\n",
        "    HAVING COUNT(*) >= 50\n",
        "    ORDER BY u.user_id, count_ratings DESC\n",
        "    \"\"\"\n",
        "    print(\"Favourite Genres for Frequent Users\")\n",
        "    spark.sql(sql_query_iii).show(10)\n",
        "\n",
        "    # iv) Find all the users with age that is less than 20 years old\n",
        "    sql_query_iv = \"\"\"\n",
        "    SELECT *\n",
        "    FROM users\n",
        "    WHERE age < 20\n",
        "    \"\"\"\n",
        "    print(\"Users Under 20 Years Old\")\n",
        "    spark.sql(sql_query_iv).show(10)\n",
        "\n",
        "    # v) Find all the users who have the occupation “scientist” and their age is between 30 and 40 years old\n",
        "    sql_query_v = \"\"\"\n",
        "    SELECT *\n",
        "    FROM users\n",
        "    WHERE occupation = 'scientist' AND age BETWEEN 30 AND 40\n",
        "    \"\"\"\n",
        "    print(\"Scientists between 30-40 Years Old\")\n",
        "    spark.sql(sql_query_v).show(10)\n",
        "\n",
        "    # Stop the Spark session\n",
        "    spark.stop()\n"
      ],
      "metadata": {
        "id": "jrbMLx50WvOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}